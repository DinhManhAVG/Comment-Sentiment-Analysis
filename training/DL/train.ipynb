{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, hamming_loss, accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5406c",
   "metadata": {},
   "source": [
    "### --- 1. Load và chuẩn bị dữ liệu ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c34367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử file data của bạn tên là 'comments.csv'\n",
    "try:\n",
    "    df = pd.read_csv('comments.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'comments.csv' not found. Please provide the correct file path.\")\n",
    "    # Tạo DataFrame mẫu nếu không có file\n",
    "    data = {'product_id': ['honor-x8b', 'honor-x8b', 'honor-x8b', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12', 'iphone-12'],\n",
    "            'comment': ['Đừng mua, ko có linh kiện.', 'Mua online bên này báo ngoài ip ra thì hàng ko có full box...', 'Mạng yếu hay mất sóng...', 'Mua máy lướt được 2 hôm đã lỗi loa ngoài...', 'Mới mua mà dễ nóng quá...', 'Hàng trưng bày. Sạc 4x lần...', 'Mặt kính cảm ứng cường lực nhưng ko chống sước...', 'Mai mốt mang đi bảo hành đây...', 'Mới mua được 3 tháng bây giờ phát hiện ra bức xạ...', 'Mới mua được 1 tháng thì xảy ra tình trạng tụt pin...', 'Bắt mạng rất yếu.', 'Tệ pin dại quá'],\n",
    "            'comment_clean_stage1': ['đừng mua, không có linh kiện.', 'mua online bên này báo ngoài iphone ra thì hàng không có full box...', 'mạng yếu hay mất sóng...', 'mua máy lướt được hai hôm đã lỗi loa ngoài...', 'mới mua mà dễ nóng quá...', 'hàng trưng bày. sạc 4 lần...', 'mặt kính cảm ứng cường lực nhưng không chống sước...', 'mai mốt mang đi bảo hành đây...', 'mới mua được ba tháng bây giờ phát hiện ra bức xạ...', 'mới mua được một tháng thì xảy ra tình trạng tụt pin...', 'bắt mạng rất yếu.', 'tệ pin dại quá!.'],\n",
    "            'comment_clean_stage2': ['đừng mua không linh_kiện', 'mua online bên báo iphone hàng không full box máy tạm ổn hơi nhẹ hơn xiaomi tuy_nhiên gọi mạng wifi 4g đứng hình suốt mà check máy vẫn gọi ổn không phải đường truyền mạng kém không thời_gian cửa_hàng giờ gọi hỏi bảo cửa_hàng bảo_hành mới mua được hai hôm giờ muốn đổi iphone 13 được đổi không hay hỗ_trợ đổi không shop máy gọi không thấy hình chập_chờn hoài dù mạng vẫn ổn_định sao', 'mạng yếu hay mất sóng đổi máy được không', 'mua máy lướt được hai hôm lỗi loa lúc bán nhân_viên không báo lỗi loa phải gửi đi bảo_hành mất thời_gian tốn tiền dán cường_lực pda', 'mới mua mà dễ nóng quá sạc nhất_là bật máy_ảnh phút nóng', 'hàng trưng_bày sạc bốn lần mà pin tụt', 'mặt kính cảm_ứng cường_lực nhưng không chống xước dùng được hai tháng màn_hình xước không chỗ trống thua màn_hình iphone', 'mai_mốt mang đi bảo_hành tự_nhiên sọc màn cho_dù không rơi', 'mới mua được tháng phát_hiện bức_xạ đổi được không', 'mới mua được tháng xảy tình_trạng tụt pin đêm tắt toàn_bộ ứng_dụng mạng bluetooth chả nổi quá tệ', 'bắt mạng rất yếu', 'tệ pin dại quá'],\n",
    "            'rating': [1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1],\n",
    "            'positive': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            'negative': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Using sample data.\")\n",
    "\n",
    "\n",
    "# Đảm bảo cột comment sạch không bị NaN\n",
    "df['comment_clean_stage2'] = df['comment_clean_stage2'].fillna('').astype(str)\n",
    "\n",
    "# Tạo nhãn đa nhãn\n",
    "labels = df[['positive', 'negative']].values\n",
    "comments = df['comment_clean_stage2'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb39c37",
   "metadata": {},
   "source": [
    "### --- 2. Tokenization và Padding ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 10000  # Giới hạn số lượng từ trong từ điển\n",
    "MAX_SEQUENCE_LENGTH = 150 # Độ dài tối đa của một chuỗi (comment)\n",
    "EMBEDDING_DIM = 128    # Kích thước vector embedding\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(comments)\n",
    "sequences = tokenizer.texts_to_sequences(comments)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Found {len(word_index)} unique tokens.\")\n",
    "\n",
    "data_padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545c588",
   "metadata": {},
   "source": [
    "### --- 3. Chia dữ liệu ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(data_padded, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train data shape: {X_train.shape}, Train labels shape: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, Val labels shape: {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b3867",
   "metadata": {},
   "source": [
    "### --- 4. Định nghĩa các mô hình ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm_model(vocab_size, embedding_dim, max_length, num_labels=2):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  input_length=max_length),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)), # Giữ lại chuỗi cho lớp tiếp theo hoặc pooling\n",
    "        # GlobalMaxPooling1D(), # Có thể thêm pooling nếu muốn\n",
    "        Bidirectional(LSTM(32)), # Lớp LSTM cuối không cần return_sequences=True\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_labels, activation='sigmoid') # Sigmoid cho multi-label\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', # Phù hợp cho multi-label\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy', tf.keras.metrics.AUC(name='auc')]) # AUC là metric tốt\n",
    "    return model\n",
    "\n",
    "def build_bigru_model(vocab_size, embedding_dim, max_length, num_labels=2):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  input_length=max_length),\n",
    "        Bidirectional(GRU(64, return_sequences=True)),\n",
    "        # GlobalMaxPooling1D(),\n",
    "        Bidirectional(GRU(32)),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_labels, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913dbb65",
   "metadata": {},
   "source": [
    "### --- 5. Huấn luyện và Đánh giá ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122565a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    \"BiLSTM\": build_bilstm_model(MAX_NUM_WORDS, EMBEDDING_DIM, MAX_SEQUENCE_LENGTH),\n",
    "    \"BiGRU\": build_bigru_model(MAX_NUM_WORDS, EMBEDDING_DIM, MAX_SEQUENCE_LENGTH)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "histories = {}\n",
    "training_times = {}\n",
    "prediction_times = {}\n",
    "\n",
    "BATCH_SIZE = 32 # Giảm nếu gặp lỗi OOM (Out of Memory)\n",
    "EPOCHS = 50     # Số epochs lớn, dùng EarlyStopping để dừng sớm\n",
    "\n",
    "# Tạo thư mục lưu model weights\n",
    "if not os.path.exists('model_checkpoints'):\n",
    "    os.makedirs('model_checkpoints')\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=f'model_checkpoints/{model_name}_best.keras', # Sử dụng định dạng .keras mới\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        verbose=2) # verbose=2 cho ít output hơn\n",
    "    end_time = time.time()\n",
    "    training_times[model_name] = end_time - start_time\n",
    "    histories[model_name] = history\n",
    "\n",
    "    print(f\"\\n--- Evaluating {model_name} on Test Set ---\")\n",
    "    # Load lại best model đã lưu\n",
    "    best_model = tf.keras.models.load_model(f'model_checkpoints/{model_name}_best.keras')\n",
    "\n",
    "    loss, binary_acc, auc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"{model_name} Test Loss: {loss:.4f}\")\n",
    "    print(f\"{model_name} Test Binary Accuracy: {binary_acc:.4f}\")\n",
    "    print(f\"{model_name} Test AUC: {auc:.4f}\")\n",
    "\n",
    "    # Dự đoán và tính toán các metrics khác\n",
    "    start_pred_time = time.time()\n",
    "    y_pred_prob = best_model.predict(X_test)\n",
    "    end_pred_time = time.time()\n",
    "    prediction_times[model_name] = end_pred_time - start_pred_time\n",
    "\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int) # Ngưỡng 0.5 để chuyển prob -> class\n",
    "\n",
    "    # Metrics chi tiết (Sklearn)\n",
    "    accuracy = accuracy_score(y_test, y_pred) # Subset accuracy\n",
    "    hamming = hamming_loss(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_samples = f1_score(y_test, y_pred, average='samples')\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\n{model_name} Detailed Test Metrics:\")\n",
    "    print(f\"  Subset Accuracy (Exact Match Ratio): {accuracy:.4f}\")\n",
    "    print(f\"  Hamming Loss (Lower is better): {hamming:.4f}\")\n",
    "    print(f\"  F1 Score (Micro): {f1_micro:.4f}\")\n",
    "    print(f\"  F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"  F1 Score (Samples): {f1_samples:.4f}\") # Trung bình F1 của từng mẫu\n",
    "    print(f\"  Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"  Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(\"\\nClassification Report (Label-wise):\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['positive', 'negative'], zero_division=0))\n",
    "\n",
    "    results[model_name] = {\n",
    "        'loss': loss,\n",
    "        'binary_accuracy': binary_acc,\n",
    "        'auc': auc,\n",
    "        'subset_accuracy': accuracy,\n",
    "        'hamming_loss': hamming,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_samples': f1_samples,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'training_time': training_times[model_name],\n",
    "        'prediction_time_per_batch': prediction_times[model_name] / len(X_test) if len(X_test)>0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63363413",
   "metadata": {},
   "source": [
    "### --- 6. So sánh và Vẽ biểu đồ ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Comparison Summary ---\")\n",
    "results_df = pd.DataFrame(results).T # Transpose để model thành hàng\n",
    "print(results_df)\n",
    "\n",
    "# Vẽ biểu đồ lịch sử huấn luyện (loss và accuracy)\n",
    "def plot_history(histories, metric='binary_accuracy', auc_metric='auc'):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Training & Validation Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for model_name, history in histories.items():\n",
    "        plt.plot(history.history[metric], label=f'{model_name} Train Acc')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'{model_name} Val Acc', linestyle='--')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Training & Validation Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for model_name, history in histories.items():\n",
    "        plt.plot(history.history['loss'], label=f'{model_name} Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label=f'{model_name} Val Loss', linestyle='--')\n",
    "        # Optional: Plot AUC if available\n",
    "        if auc_metric in history.history:\n",
    "            plt.plot(history.history[auc_metric], label=f'{model_name} Train AUC', linestyle=':')\n",
    "        if f'val_{auc_metric}' in history.history:\n",
    "             plt.plot(history.history[f'val_{auc_metric}'], label=f'{model_name} Val AUC', linestyle='-.')\n",
    "\n",
    "    plt.title('Model Loss & AUC')\n",
    "    plt.ylabel('Loss / AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17338a53",
   "metadata": {},
   "source": [
    "### --- 7. Ví dụ dự đoán trên comment mới ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, max_length):\n",
    "    # Làm sạch và chuẩn bị text giống như lúc train (giả sử đã có hàm clean_text)\n",
    "    # clean_text = text # Tạm thời bỏ qua bước làm sạch phức tạp nếu không có sẵn\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    labels = (prediction > 0.5).astype(int)[0] # Lấy dự đoán cho mẫu đầu tiên (và duy nhất)\n",
    "    return {\"positive\": labels[0], \"negative\": labels[1]}, prediction[0]\n",
    "\n",
    "# Chọn model tốt nhất dựa trên validation (hoặc test) performance để dự đoán\n",
    "best_model_name = results_df['f1_macro'].idxmax() # Ví dụ chọn theo F1 Macro cao nhất\n",
    "print(f\"\\nUsing best model for prediction: {best_model_name}\")\n",
    "best_model = tf.keras.models.load_model(f'model_checkpoints/{best_model_name}_best.keras')\n",
    "\n",
    "# Ví dụ\n",
    "new_comment_positive = \"điện thoại này dùng rất mượt pin trâu chụp ảnh đẹp lắm\"\n",
    "new_comment_negative = \"máy lag quá dùng chán không tả nổi hay bị sập nguồn\"\n",
    "new_comment_mixed = \"camera ổn nhưng pin tụt nhanh kinh khủng\"\n",
    "new_comment_neutral = \"giao hàng đúng hẹn đóng gói cẩn thận\" # Mô hình có thể khó đoán đúng neutral\n",
    "\n",
    "for comment in [new_comment_positive, new_comment_negative, new_comment_mixed, new_comment_neutral]:\n",
    "    pred_labels, pred_probs = predict_sentiment(comment, best_model, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "    print(f\"\\nComment: '{comment}'\")\n",
    "    print(f\"  Predicted Probabilities (Pos, Neg): ({pred_probs[0]:.3f}, {pred_probs[1]:.3f})\")\n",
    "    print(f\"  Predicted Labels: {pred_labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
