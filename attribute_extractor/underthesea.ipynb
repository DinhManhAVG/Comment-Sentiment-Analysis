{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0cd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import dependency_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40679c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_blacklist = {\"tôi\", \"mình\", \"em\", \"anh\", \"chị\", \"bạn\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18095232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes(text, subject_blacklist=None, debug=False):\n",
    "    \"\"\"\n",
    "    Trích xuất các cặp (chủ ngữ -> vị ngữ mô tả) từ kết quả dependency parse,\n",
    "    loại bỏ các chủ ngữ nằm trong blacklist.\n",
    "\n",
    "    Args:\n",
    "        dep_parse_output (list): Danh sách các tuple từ dependency_parse().\n",
    "                                 Ví dụ: [('Sản phẩm', 3, 'nsubj'), ...]\n",
    "        subject_blacklist (set, optional): Tập hợp các chủ ngữ (dạng chữ thường)\n",
    "                                           cần loại bỏ. Mặc định là {'tôi', 'mình', ...}.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary chứa các cặp (chủ ngữ -> vị ngữ mô tả).\n",
    "              Ví dụ: {'Sản phẩm': 'tốt nhất', 'pin': 'dùng lâu'}\n",
    "    \"\"\"\n",
    "\n",
    "    parse_output = dependency_parse(text)\n",
    "\n",
    "    # In ra để dễ theo dõi (tùy chọn)\n",
    "    if debug:\n",
    "        print(\"Kết quả Dependency Parse:\")\n",
    "        for item in parse_output:\n",
    "            print(item)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    # Xử lý kết quả\n",
    "    results = {}\n",
    "\n",
    "    # Tạo một danh sách các token với chỉ số 0-based để dễ truy cập\n",
    "    # Thêm trường 'id' (chỉ số gốc 0-based) và chuyển 'head' thành 0-based\n",
    "    indexed_parse = []\n",
    "    for i, (word, head_idx, rel) in enumerate(parse_output):\n",
    "        indexed_parse.append(\n",
    "            {\n",
    "                \"id\": i,\n",
    "                \"word\": word,\n",
    "                \"head\": head_idx\n",
    "                - 1,  # Chuyển sang 0-based index (-1 nếu head là 0/root)\n",
    "                \"rel\": rel,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Tìm các chủ ngữ (nsubj)\n",
    "    for i, token in enumerate(indexed_parse):\n",
    "        if token[\"rel\"] == \"nsubj\":\n",
    "            subject_word = token[\"word\"]\n",
    "            head_index = token[\"head\"]  # Chỉ số 0-based của head\n",
    "\n",
    "            subject_word_lower = (\n",
    "                subject_word.lower()\n",
    "            )  # Chuyển sang chữ thường để so sánh\n",
    "\n",
    "            # === BƯỚC LỌC: Bỏ qua nếu chủ ngữ nằm trong blacklist ===\n",
    "            if subject_word_lower in subject_blacklist:\n",
    "                if debug:\n",
    "                    print(f\"-> Bỏ qua chủ ngữ '{subject_word}' vì nằm trong blacklist.\")\n",
    "                \n",
    "                continue  # Bỏ qua vòng lặp này và xử lý token tiếp theo\n",
    "\n",
    "            # Đảm bảo head_index hợp lệ\n",
    "            if 0 <= head_index < len(indexed_parse):\n",
    "                head_token = indexed_parse[head_index]\n",
    "                predicate_parts = [head_token]  # Bắt đầu cụm vị ngữ bằng head\n",
    "\n",
    "                # Tìm các thành phần phụ thuộc trực tiếp vào head_token này\n",
    "                # để mở rộng cụm vị ngữ (ví dụ: acomp, advmod, obj...)\n",
    "                for potential_dependent in indexed_parse:\n",
    "                    # Nếu token này phụ thuộc vào head_token hiện tại\n",
    "                    if potential_dependent[\"head\"] == head_token[\"id\"]:\n",
    "                        # Chỉ lấy các quan hệ bổ nghĩa cho vị ngữ\n",
    "                        # (Bạn có thể thêm các loại quan hệ khác nếu cần)\n",
    "                        if potential_dependent[\"rel\"] in [\n",
    "                            \"acomp\",\n",
    "                            \"advmod\",\n",
    "                            \"obj\",\n",
    "                            \"xcomp\",\n",
    "                        ]:\n",
    "                            predicate_parts.append(potential_dependent)\n",
    "\n",
    "                # Sắp xếp các phần của vị ngữ theo thứ tự xuất hiện trong câu gốc\n",
    "                predicate_parts.sort(key=lambda x: x[\"id\"])\n",
    "\n",
    "                # Ghép các từ thành chuỗi vị ngữ\n",
    "                predicate_string = \" \".join([p[\"word\"] for p in predicate_parts])\n",
    "\n",
    "                # Lưu kết quả (chuyển sang chữ thường cho nhất quán)\n",
    "                results[subject_word.lower()] = predicate_string.lower()\n",
    "\n",
    "    # In kết quả cuối cùng\n",
    "    if debug:\n",
    "        print(\"Kết quả trích xuất:\")\n",
    "        for subject, predicate in results.items():\n",
    "            print(f\"{subject} -> {predicate}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1f9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả Dependency Parse:\n",
      "('Sản phẩm', 2, 'nsubj')\n",
      "('tốt', 0, 'root')\n",
      "('nhất', 2, 'advmod')\n",
      "('mà', 7, 'mark')\n",
      "('tôi', 7, 'nsubj')\n",
      "('từng', 7, 'advmod')\n",
      "('mua', 2, 'ccomp')\n",
      "(',', 10, 'punct')\n",
      "('pin', 10, 'nsubj')\n",
      "('dùng', 7, 'conj')\n",
      "('lâu', 10, 'acomp')\n",
      "('nhưng', 15, 'mark')\n",
      "('giá', 15, 'nsubj')\n",
      "('hơi', 15, 'advmod')\n",
      "('cao', 10, 'conj')\n",
      "(',', 18, 'punct')\n",
      "('kết nối', 18, 'nummod')\n",
      "('mạng', 15, 'conj')\n",
      "('kém', 18, 'nmod')\n",
      "(',', 21, 'punct')\n",
      "('máy', 18, 'conj')\n",
      "('nóng', 21, 'amod')\n",
      "(',', 24, 'punct')\n",
      "('nhân viên', 18, 'conj')\n",
      "('tư vấn', 24, 'acl:subj')\n",
      "('nhiệt tình', 25, 'compound:svc')\n",
      "--------------------\n",
      "-> Bỏ qua chủ ngữ 'tôi' vì nằm trong blacklist.\n",
      "Kết quả trích xuất:\n",
      "sản phẩm -> tốt nhất\n",
      "pin -> dùng lâu\n",
      "giá -> hơi cao\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sản phẩm': 'tốt nhất', 'pin': 'dùng lâu', 'giá': 'hơi cao'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Sản phẩm tốt nhất mà tôi từng mua, pin dùng lâu nhưng giá hơi cao, kết nối mạng kém, máy nóng, nhân viên tư vấn nhiệt tình\"\n",
    "\n",
    "extract_attributes(sentence, subject_blacklist, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb514436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả Dependency Parse:\n",
      "('Cũng', 2, 'advmod')\n",
      "('tạm', 0, 'root')\n",
      "('.', 2, 'punct')\n",
      "('Hàng', 8, 'nsubj')\n",
      "('trưng bày', 4, 'nmod')\n",
      "('có', 8, 'advmod')\n",
      "('bị', 8, 'aux')\n",
      "('xước', 2, 'parataxis')\n",
      "('màn hình', 8, 'obj')\n",
      "('rồi', 8, 'advmod')\n",
      "('nhưng', 14, 'mark')\n",
      "('mọi', 13, 'det')\n",
      "('thứ', 14, 'nsubj')\n",
      "('dùng', 2, 'conj')\n",
      "('ổn', 14, 'obj')\n",
      "('.', 14, 'punct')\n",
      "('Pin', 18, 'nummod')\n",
      "('hơi đuối', 14, 'obj')\n",
      "('.', 20, 'punct')\n",
      "('Tóm lại', 14, 'conj')\n",
      "('giá', 20, 'nmod')\n",
      "('rẻ', 21, 'acl:subj')\n",
      "('hơn', 22, 'advmod:adj')\n",
      "('mọi', 25, 'det')\n",
      "('chỗ', 22, 'obl:adj')\n",
      "(',', 27, 'punct')\n",
      "('máy', 25, 'conj')\n",
      "('zin all', 27, 'compound')\n",
      "(',', 30, 'punct')\n",
      "('chế độ', 14, 'conj')\n",
      "('bảo hành', 30, 'compound')\n",
      "('đổi', 31, 'acl:subj')\n",
      "('trả', 32, 'xcomp')\n",
      "('kém', 33, 'acomp')\n",
      "('hơn', 36, 'advmod:adj')\n",
      "('chỗ', 34, 'obl:adj')\n",
      "('khác', 36, 'amod')\n",
      "('.', 2, 'punct')\n",
      "('OK', 2, 'punct')\n",
      "--------------------\n",
      "Kết quả trích xuất:\n",
      "hàng -> có xước màn hình rồi\n",
      "thứ -> dùng ổn hơi đuối\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hàng': 'có xước màn hình rồi', 'thứ': 'dùng ổn hơi đuối'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_attributes(\"Cũng tạm. Hàng trưng bày có bị xước màn hình rồi nhưng mọi thứ dùng ổn. Pin hơi đuối. Tóm lại giá rẻ hơn mọi chỗ, máy zin all, chế độ bảo hành đổi trả kém hơn chỗ khác. OK\", subject_blacklist, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
